#!/usr/bin/env python3
"""
í•˜ì´ë¸Œë¦¬ë“œ ë¼ì¸íŠ¸ë ˆì´ì‹± (CV ì£¼ë„ + ML ë³´ì¡°)
CV ë°©ì‹ì„ ì£¼ë¡œ ì‚¬ìš©í•˜ê³ , MLì€ íŠ¹ì • ìƒí™©ì—ì„œë§Œ ì‚¬ìš©í•©ë‹ˆë‹¤.

ì „ëµ:
- ê¸°ë³¸: CV ë°©ì‹ìœ¼ë¡œ ë¹ ë¥¸ ì œì–´ (ëŒ€ë¶€ë¶„ì˜ ê²½ìš°)
- ML ì‚¬ìš© ì‹œì :
  1. CVê°€ ë¼ì¸ì„ ì°¾ì§€ ëª»í•  ë•Œ (noline ê°ì§€)
  2. íŠ¸ë˜í”½ ë¼ì´íŠ¸ ê°ì§€ (ë” ì •í™•í•¨)
  3. ë³µì¡í•œ ê³¡ì„  êµ¬ê°„ (ì„ íƒì )

ì‚¬ìš©ë²•:
    python3 line_tracing_hybrid.py
"""

import cv2
import numpy as np
import time
import os
from picamera2 import Picamera2
import RPi.GPIO as GPIO

# ML ëª¨ë¸ ì‚¬ìš© ì—¬ë¶€
try:
    import tflite_runtime.interpreter as tflite
    USE_ML = True
    MODEL_PATH = "model.tflite"
    LABELS = ["green", "left", "middle", "noline", "red", "right"]
except ImportError:
    USE_ML = False
    print("âš  TFLiteë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. CV ë°©ì‹ë§Œ ì‚¬ìš©í•©ë‹ˆë‹¤.")

# ==================== GPIO ì„¤ì • ====================
DIR_PIN = 16
PWM_PIN = 12
SERVO_PIN = 13

MOTOR_FREQ = 1000
SERVO_FREQ = 50
SERVO_MAX_DUTY = 12
SERVO_MIN_DUTY = 3

# ì†ë„ ì„¤ì •
SPEED_NORMAL = 50
SPEED_SLOW = 40
SPEED_FAST = 60
SERVO_ANGLE_CENTER = 90
SERVO_ANGLE_MAX = 135
SERVO_ANGLE_MIN = 45

# ==================== CV ì´ë¯¸ì§€ ì²˜ë¦¬ ì„¤ì • ====================
IMG_WIDTH = 320  # CV ì²˜ë¦¬ìš© (ë¹ ë¦„)
IMG_HEIGHT = 240
ROI_TOP = 0.4
ROI_BOTTOM = 1.0

# ML ì´ë¯¸ì§€ ì²˜ë¦¬ ì„¤ì •
ML_IMG_SIZE = 224  # ML ëª¨ë¸ ì…ë ¥ í¬ê¸°

# ë¼ì¸ ê²€ì¶œ ì„¤ì •
WHITE_THRESHOLD = 200
MIN_LINE_WIDTH = 2
MAX_LINE_WIDTH = 20

# PID ì œì–´ ì„¤ì •
Kp = 0.8
Ki = 0.0
Kd = 0.1

# í•˜ì´ë¸Œë¦¬ë“œ ì „ëµ ì„¤ì •
CV_CONFIDENCE_THRESHOLD = 0.7  # CV ì‹ ë¢°ë„ ì„ê³„ê°’
ML_USE_INTERVAL = 3  # MLì„ ëª‡ í”„ë ˆì„ë§ˆë‹¤ ì‚¬ìš©í• ì§€ (3 = 3í”„ë ˆì„ë§ˆë‹¤ 1ë²ˆ)
ML_CONFIDENCE_THRESHOLD = 0.6  # ML ì‹ ë¢°ë„ ì„ê³„ê°’

# ==================== GPIO ì´ˆê¸°í™” ====================
GPIO.setmode(GPIO.BCM)
GPIO.setup([DIR_PIN, PWM_PIN, SERVO_PIN], GPIO.OUT)

motor_pwm = GPIO.PWM(PWM_PIN, MOTOR_FREQ)
servo_pwm = GPIO.PWM(SERVO_PIN, SERVO_FREQ)
motor_pwm.start(0)
servo_pwm.start(0)

# PID ë³€ìˆ˜
prev_error = 0
integral = 0

# ML ê´€ë ¨ ë³€ìˆ˜
ml_interpreter = None
ml_inp = None
ml_out = None
frame_count = 0

# ==================== ëª¨í„° ì œì–´ í•¨ìˆ˜ ====================
def set_servo_angle(degree):
    """ì„œë³´ ëª¨í„° ê°ë„ ì„¤ì •"""
    degree = max(SERVO_ANGLE_MIN, min(SERVO_ANGLE_MAX, degree))
    duty = SERVO_MIN_DUTY + (degree * (SERVO_MAX_DUTY - SERVO_MIN_DUTY) / 180.0)
    servo_pwm.ChangeDutyCycle(duty)

def move_forward(speed):
    """ì „ì§„"""
    GPIO.output(DIR_PIN, GPIO.HIGH)
    motor_pwm.ChangeDutyCycle(speed)

def stop_motor():
    """ì •ì§€"""
    motor_pwm.ChangeDutyCycle(0)

# ==================== CV ì´ë¯¸ì§€ ì²˜ë¦¬ í•¨ìˆ˜ ====================
def preprocess_image_cv(frame):
    """CVìš© ì´ë¯¸ì§€ ì „ì²˜ë¦¬"""
    img = cv2.resize(frame, (IMG_WIDTH, IMG_HEIGHT))
    h, w = img.shape[:2]
    roi_top = int(h * ROI_TOP)
    roi_bottom = int(h * ROI_BOTTOM)
    roi = img[roi_top:roi_bottom, :]
    return roi, roi_top

def detect_line_cv(roi):
    """CV ë°©ì‹ ë¼ì¸ ê²€ì¶œ"""
    gray = cv2.cvtColor(roi, cv2.COLOR_RGB2GRAY)
    blurred = cv2.GaussianBlur(gray, (5, 5), 0)
    _, binary = cv2.threshold(blurred, WHITE_THRESHOLD, 255, cv2.THRESH_BINARY)

    kernel = np.ones((3, 3), np.uint8)
    binary = cv2.morphologyEx(binary, cv2.MORPH_CLOSE, kernel)

    h, w = binary.shape
    bottom_center = find_line_center(binary, int(h * 0.8))
    top_center = find_line_center(binary, int(h * 0.2))

    # ì‹ ë¢°ë„ ê³„ì‚° (ë¼ì¸ í­ê³¼ í”½ì…€ ìˆ˜ ê¸°ë°˜)
    confidence = 0.0
    if bottom_center is not None:
        row = binary[int(h * 0.8), :]
        white_pixels = np.where(row > 128)[0]
        if len(white_pixels) > 0:
            line_width = white_pixels[-1] - white_pixels[0]
            # ë¼ì¸ í­ì´ ì ì ˆí•˜ë©´ ë†’ì€ ì‹ ë¢°ë„
            if MIN_LINE_WIDTH <= line_width <= MAX_LINE_WIDTH:
                confidence = 0.9
            else:
                confidence = 0.5

    return binary, top_center, bottom_center, confidence

def find_line_center(binary, y_pos):
    """íŠ¹ì • y ìœ„ì¹˜ì—ì„œ ë¼ì¸ì˜ ì¤‘ì‹¬ x ì¢Œí‘œ ì°¾ê¸°"""
    row = binary[y_pos, :]
    white_pixels = np.where(row > 128)[0]

    if len(white_pixels) == 0:
        return None

    center = int(np.mean(white_pixels))
    line_width = white_pixels[-1] - white_pixels[0]

    if line_width < MIN_LINE_WIDTH or line_width > MAX_LINE_WIDTH:
        return None

    return center

def calculate_error_cv(bottom_center, top_center, img_center):
    """CV ë°©ì‹ ì—ëŸ¬ ê³„ì‚°"""
    if bottom_center is None:
        return None, 0.0

    error = bottom_center - img_center

    if top_center is not None:
        direction = top_center - bottom_center
        error = error + direction * 0.3

    confidence = 0.9 if bottom_center is not None else 0.0
    return error, confidence

# ==================== ML ì´ë¯¸ì§€ ì²˜ë¦¬ í•¨ìˆ˜ ====================
def preprocess_image_ml(frame_rgb):
    """MLìš© ì´ë¯¸ì§€ ì „ì²˜ë¦¬"""
    img = cv2.resize(frame_rgb, (ML_IMG_SIZE, ML_IMG_SIZE), interpolation=cv2.INTER_AREA)
    img = img.astype(np.float32) / 255.0
    return img[None, ...]

def predict_ml(frame_rgb):
    """ML ëª¨ë¸ë¡œ ì˜ˆì¸¡"""
    global ml_interpreter, ml_inp, ml_out

    if not USE_ML or ml_interpreter is None:
        return None, 0.0

    try:
        x = preprocess_image_ml(frame_rgb)
        ml_interpreter.set_tensor(ml_inp["index"], x)
        ml_interpreter.invoke()
        probs = ml_interpreter.get_tensor(ml_out["index"])[0]
        pred_id = int(np.argmax(probs))
        pred_label = LABELS[pred_id]
        confidence = probs[pred_id]
        return pred_label, confidence
    except Exception as e:
        print(f"âš  ML ì˜ˆì¸¡ ì˜¤ë¥˜: {e}")
        return None, 0.0

# ==================== íŠ¸ë˜í”½ ë¼ì´íŠ¸ ê°ì§€ ====================
def detect_traffic_light_cv(frame):
    """CV ë°©ì‹ íŠ¸ë˜í”½ ë¼ì´íŠ¸ ê°ì§€"""
    h, w = frame.shape[:2]
    roi = frame[0:int(h*0.3), :]

    hsv = cv2.cvtColor(roi, cv2.COLOR_RGB2HSV)

    # ë¹¨ê°„ìƒ‰
    red_lower1 = np.array([0, 50, 50])
    red_upper1 = np.array([10, 255, 255])
    red_lower2 = np.array([170, 50, 50])
    red_upper2 = np.array([180, 255, 255])
    red_mask1 = cv2.inRange(hsv, red_lower1, red_upper1)
    red_mask2 = cv2.inRange(hsv, red_lower2, red_upper2)
    red_mask = cv2.bitwise_or(red_mask1, red_mask2)

    # ì´ˆë¡ìƒ‰
    green_lower = np.array([40, 50, 50])
    green_upper = np.array([80, 255, 255])
    green_mask = cv2.inRange(hsv, green_lower, green_upper)

    red_pixels = cv2.countNonZero(red_mask)
    green_pixels = cv2.countNonZero(green_mask)
    threshold = 100

    if red_pixels > threshold:
        return 'red', 0.8
    elif green_pixels > threshold:
        return 'green', 0.8
    else:
        return None, 0.0

# ==================== PID ì œì–´ ====================
def pid_control(error):
    """PID ì œì–´ë¡œ ì„œë³´ ê°ë„ ê³„ì‚°"""
    global prev_error, integral

    if error is None:
        return None

    integral += error
    integral = max(-100, min(100, integral))
    derivative = error - prev_error

    output = Kp * error + Ki * integral + Kd * derivative

    max_error = IMG_WIDTH / 2
    angle_offset = (error / max_error) * 45
    angle = SERVO_ANGLE_CENTER - angle_offset
    angle = max(SERVO_ANGLE_MIN, min(SERVO_ANGLE_MAX, angle))

    prev_error = error
    return angle

# ==================== ë©”ì¸ í•¨ìˆ˜ ====================
def main():
    global ml_interpreter, ml_inp, ml_out, frame_count

    print("=" * 60)
    print("í•˜ì´ë¸Œë¦¬ë“œ ë¼ì¸íŠ¸ë ˆì´ì‹± (CV ì£¼ë„ + ML ë³´ì¡°)")
    print("=" * 60)

    # ML ëª¨ë¸ ë¡œë“œ
    if USE_ML and os.path.exists(MODEL_PATH):
        print(f"ML ëª¨ë¸ ë¡œë“œ ì¤‘: {MODEL_PATH}")
        try:
            ml_interpreter = tflite.Interpreter(model_path=MODEL_PATH)
            ml_interpreter.allocate_tensors()
            ml_inp = ml_interpreter.get_input_details()[0]
            ml_out = ml_interpreter.get_output_details()[0]
            print("âœ“ ML ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
        except Exception as e:
            print(f"âš  ML ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
            ml_interpreter = None
    else:
        print("âš  ML ëª¨ë¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. CV ë°©ì‹ë§Œ ì‚¬ìš©í•©ë‹ˆë‹¤.")
        ml_interpreter = None

    # ì¹´ë©”ë¼ ì´ˆê¸°í™”
    print("ì¹´ë©”ë¼ ì´ˆê¸°í™” ì¤‘...")
    picam2 = Picamera2()
    config = picam2.create_preview_configuration(
        main={"format": "RGB888", "size": (640, 480)}
    )
    picam2.configure(config)
    picam2.start()
    time.sleep(1)
    print("âœ“ ì¹´ë©”ë¼ ì´ˆê¸°í™” ì™„ë£Œ\n")

    # ì´ˆê¸° ì„¤ì •
    set_servo_angle(SERVO_ANGLE_CENTER)
    time.sleep(0.1)

    img_center = IMG_WIDTH / 2
    lost_line_count = 0
    max_lost_count = 10
    last_ml_prediction = "middle"
    ml_prediction_buffer = []

    print("ë¼ì¸íŠ¸ë ˆì´ì‹± ì‹œì‘! (q í‚¤ë¡œ ì¢…ë£Œ)")
    print("=" * 60)

    try:
        while True:
            frame_count += 1
            start_time = time.time()

            # í”„ë ˆì„ ìº¡ì²˜
            frame_rgb = picam2.capture_array()

            # íŠ¸ë˜í”½ ë¼ì´íŠ¸ ê°ì§€ (CV + ML)
            traffic_light_cv, cv_conf = detect_traffic_light_cv(frame_rgb)
            traffic_light = traffic_light_cv

            # MLë¡œë„ í™•ì¸ (ì£¼ê¸°ì ìœ¼ë¡œ)
            if ml_interpreter and frame_count % ML_USE_INTERVAL == 0:
                ml_pred, ml_conf = predict_ml(frame_rgb)
                if ml_pred in ['red', 'green'] and ml_conf > ML_CONFIDENCE_THRESHOLD:
                    traffic_light = ml_pred
                    print(f"ğŸŸ¢ ML íŠ¸ë˜í”½ ë¼ì´íŠ¸ ê°ì§€: {ml_pred} (ì‹ ë¢°ë„: {ml_conf:.2f})")

            if traffic_light == 'red':
                print("ğŸ”´ ë¹¨ê°„ë¶ˆ ê°ì§€ - ì •ì§€")
                stop_motor()
                set_servo_angle(SERVO_ANGLE_CENTER)
                while True:
                    frame_rgb = picam2.capture_array()
                    traffic_light_cv, _ = detect_traffic_light_cv(frame_rgb)
                    if ml_interpreter and frame_count % 2 == 0:
                        ml_pred, ml_conf = predict_ml(frame_rgb)
                        if ml_pred == 'green' and ml_conf > ML_CONFIDENCE_THRESHOLD:
                            traffic_light_cv = 'green'
                    if traffic_light_cv == 'green':
                        print("ğŸŸ¢ ì´ˆë¡ë¶ˆ ê°ì§€ - ì¬ì‹œì‘")
                        time.sleep(0.5)
                        break
                    time.sleep(0.1)

            # CV ë°©ì‹ìœ¼ë¡œ ë¼ì¸ ê²€ì¶œ (ì£¼ë¡œ ì‚¬ìš©)
            roi, roi_top = preprocess_image_cv(frame_rgb)
            binary, top_center, bottom_center, cv_confidence = detect_line_cv(roi)
            error_cv, cv_conf = calculate_error_cv(bottom_center, top_center, img_center)

            # CV ì‹ ë¢°ë„ê°€ ë‚®ìœ¼ë©´ ML ì‚¬ìš©
            use_ml = False
            ml_pred = None
            ml_conf = 0.0

            if cv_confidence < CV_CONFIDENCE_THRESHOLD and ml_interpreter:
                if frame_count % ML_USE_INTERVAL == 0:
                    ml_pred, ml_conf = predict_ml(frame_rgb)
                    ml_prediction_buffer.append(ml_pred)
                    if len(ml_prediction_buffer) > 3:
                        ml_prediction_buffer.pop(0)

                    if ml_conf > ML_CONFIDENCE_THRESHOLD:
                        use_ml = True
                        last_ml_prediction = ml_pred

            # ì œì–´ ê²°ì •
            if use_ml and ml_pred:
                # ML ì‚¬ìš©
                if ml_pred == "left":
                    set_servo_angle(60)
                    move_forward(SPEED_NORMAL)
                elif ml_pred == "right":
                    set_servo_angle(120)
                    move_forward(SPEED_NORMAL)
                elif ml_pred == "middle":
                    set_servo_angle(SERVO_ANGLE_CENTER)
                    move_forward(SPEED_NORMAL)
                elif ml_pred == "noline":
                    # ë¼ì¸ ì—†ìœ¼ë©´ ì´ì „ ë°©í–¥ ìœ ì§€
                    if last_ml_prediction == "left":
                        set_servo_angle(60)
                    elif last_ml_prediction == "right":
                        set_servo_angle(120)
                    else:
                        set_servo_angle(SERVO_ANGLE_CENTER)
                    move_forward(SPEED_SLOW)
            elif error_cv is not None:
                # CV ì‚¬ìš© (ì£¼ë¡œ ì‚¬ìš©)
                lost_line_count = 0
                angle = pid_control(error_cv)
                if angle is not None:
                    set_servo_angle(angle)
                    move_forward(SPEED_NORMAL)
            else:
                # ë¼ì¸ì„ ì°¾ì§€ ëª»í•¨
                lost_line_count += 1
                if lost_line_count > max_lost_count:
                    print("âš  ë¼ì¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤ - ì •ì§€")
                    stop_motor()
                else:
                    # MLë¡œ ì¬ì‹œë„
                    if ml_interpreter:
                        ml_pred, ml_conf = predict_ml(frame_rgb)
                        if ml_pred and ml_conf > ML_CONFIDENCE_THRESHOLD:
                            if ml_pred == "left":
                                set_servo_angle(60)
                            elif ml_pred == "right":
                                set_servo_angle(120)
                            else:
                                set_servo_angle(SERVO_ANGLE_CENTER)
                            move_forward(SPEED_SLOW)
                    else:
                        move_forward(SPEED_SLOW)

            # í™”ë©´ í‘œì‹œ
            display_frame = frame_rgb.copy()
            h, w = display_frame.shape[:2]
            roi_top_px = int(h * ROI_TOP)
            cv2.rectangle(display_frame, (0, roi_top_px), (w, h), (0, 255, 0), 2)

            if bottom_center is not None:
                scale_x = w / IMG_WIDTH
                center_x = int(bottom_center * scale_x)
                center_y = int((h * ROI_TOP + h * 0.8) * (h / IMG_HEIGHT))
                cv2.circle(display_frame, (center_x, center_y), 5, (255, 0, 0), -1)
                cv2.line(display_frame, (w//2, center_y), (center_x, center_y), (0, 0, 255), 2)

            # ì •ë³´ í‘œì‹œ
            mode_text = "ML" if use_ml else "CV"
            info_text = f"Mode: {mode_text} | Error: {error_cv:.1f}" if error_cv is not None else f"Mode: {mode_text} | No line"
            cv2.putText(display_frame, info_text, (10, 30),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)

            if traffic_light:
                cv2.putText(display_frame, f"Traffic: {traffic_light}", (10, 60),
                           cv2.FONT_HERSHEY_SIMPLEX, 0.6,
                           (0, 0, 255) if traffic_light == 'red' else (0, 255, 0), 2)

            if ml_pred and use_ml:
                cv2.putText(display_frame, f"ML: {ml_pred} ({ml_conf:.2f})", (10, 90),
                           cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 0), 2)

            cv2.imshow("Hybrid Line Tracing", display_frame)

            if cv2.waitKey(1) & 0xFF == ord('q'):
                print("ì¢…ë£Œí•©ë‹ˆë‹¤...")
                break

            time.sleep(0.01)

    except KeyboardInterrupt:
        print("\ní‚¤ë³´ë“œ ì¸í„°ëŸ½íŠ¸ë¡œ ì¢…ë£Œí•©ë‹ˆë‹¤...")
    except Exception as e:
        print(f"ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()
    finally:
        stop_motor()
        set_servo_angle(SERVO_ANGLE_CENTER)
        picam2.stop()
        cv2.destroyAllWindows()
        motor_pwm.stop()
        servo_pwm.stop()
        GPIO.cleanup()
        print("ì‹œìŠ¤í…œ ì¢…ë£Œ ì™„ë£Œ")

if __name__ == "__main__":
    main()

