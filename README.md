# mecha_ws

ììœ¨ì£¼í–‰ ë¡œë´‡ í”„ë¡œì íŠ¸ ì›Œí¬ìŠ¤í˜ì´ìŠ¤  
Autonomous Driving Robot Project Workspace

## ğŸ“š í”„ë¡œì íŠ¸ ì •ë³´ / Project Information

**ê³¼ëª© / Course**: KAIST Mechatronics System Design (ME203)  
**í”„ë¡œì íŠ¸ / Project**: ììœ¨ì£¼í–‰ ë¡œë´‡ ì‹œìŠ¤í…œ ê°œë°œ / Autonomous Driving Robot System Development

### ğŸ“Š ìµœì¢… ë°œí‘œ ìë£Œ / Final Presentation

[í”„ë¡œì íŠ¸ ë°œí‘œ í”„ë ˆì  í…Œì´ì…˜ ë³´ê¸° / View Project Presentation](https://docs.google.com/presentation/d/e/2PACX-1vTjnZmDp63P8Fe85efcQ0TtqOuLPMxrtsNupx1o-mQ86d1k6RMgJLY8ttvDVztPpagZjweUCYdb9oF_/pub?start=false&loop=false&delayms=3000)

## ğŸ“ í”„ë¡œì íŠ¸ êµ¬ì¡° / Project Structure

```
mecha_ws/
â”œâ”€â”€ src/                        # ë©”ì¸ ì†ŒìŠ¤ ì½”ë“œ / Main source code
â”‚   â”œâ”€â”€ main.py                 # ë©”ì¸ ì‹¤í–‰ íŒŒì¼ / Main entry point
â”‚   â”œâ”€â”€ linetracing.py          # ë¼ì¸íŠ¸ë ˆì´ì‹± ë©”ì¸ ë¡œì§ / Line tracing main logic
â”‚   â”œâ”€â”€ linetracing_cv.py        # CV ê¸°ë°˜ ë¼ì¸ ê°ì§€ / CV-based line detection
â”‚   â”œâ”€â”€ linetracing_ml.py        # ML ê¸°ë°˜ ì‹ í˜¸ë“± ê°ì§€ / ML-based traffic light detection
â”‚   â”œâ”€â”€ linetracing_drive.py     # ëª¨í„°/ì„œë³´ ì œì–´ / Motor/servo control
â”‚   â”œâ”€â”€ linetracing_Judgment.py  # CV/ML íŒë‹¨ í†µí•© / CV/ML judgment integration
â”‚   â””â”€â”€ low_defense.py           # ì´ˆìŒíŒŒ ì„¼ì„œ ê¸°ë°˜ ê³ ì† ì£¼í–‰ / Ultrasonic sensor-based high-speed driving
â”‚
â”œâ”€â”€ models/                     # ML ëª¨ë¸ íŒŒì¼ / ML model files
â”‚   â””â”€â”€ gpu_model_lite.tflite   # ìµœì¢… ì‹ í˜¸ë“± ê°ì§€ ëª¨ë¸ / Final traffic light detection model
â”‚
â”œâ”€â”€ test/                       # í…ŒìŠ¤íŠ¸ íŒŒì¼ë“¤ / Test files
â”‚   â”œâ”€â”€ README_TEST_CV.md
â”‚   â”œâ”€â”€ test_cv_local.py
â”‚   â”œâ”€â”€ test_ml_local.py
â”‚   â””â”€â”€ using_both_michan_decrease_speed_straight.py
â”‚
â”œâ”€â”€ settings/                   # ì„¤ì • ë° ìœ í‹¸ë¦¬í‹° / Settings and utilities
â”‚   â”œâ”€â”€ cameracheck.py
â”‚   â”œâ”€â”€ Check_dependencies_pi.py
â”‚   â””â”€â”€ setting.sh
â”‚
â”œâ”€â”€ logs/                       # ë¡œê·¸ íŒŒì¼ ë° ì´ë¯¸ì§€ / Log files and images
â”‚   â”œâ”€â”€ line_log/               # ë¼ì¸íŠ¸ë ˆì´ì‹± ì´ë¯¸ì§€ ë¡œê·¸ / Line tracing image logs
â”‚   â”œâ”€â”€ linetracinglog.txt
â”‚   â”œâ”€â”€ linetracinglog2.txt
â”‚   â”œâ”€â”€ main.log
â”‚   â””â”€â”€ mllog
â”‚
â””â”€â”€ experiments/                # ì‹¤í—˜ ë° ì°¸ê³  ì½”ë“œ (ì‚¬ìš© ì•ˆ í•¨) / Experimental and reference code (not used)
    â”œâ”€â”€ archive/                 # ì‚¬ìš©í•˜ì§€ ì•ŠëŠ” íŒŒì¼ë“¤ / Unused files
    â”œâ”€â”€ cnn/                     # CNN í•™ìŠµ ì‹¤í—˜ / CNN training experiments
    â”œâ”€â”€ line_tracing/            # ë¼ì¸íŠ¸ë ˆì´ì‹± ì‹¤í—˜ ì½”ë“œ / Line tracing experimental code
    â”œâ”€â”€ reference/               # ìˆ˜ì—… ì‹œê°„ ì°¸ê³  ì½”ë“œ / Class reference code
    â”œâ”€â”€ simulation/              # ML ì‹œë®¬ë ˆì´ì…˜ ì‹¤í—˜ / ML simulation experiments
    â”œâ”€â”€ track_old/               # ê¸°ì¡´ íŠ¸ë™ ì£¼í–‰ ì½”ë“œ / Old track driving code
    â””â”€â”€ Yeonsu_track/            # ë²½ ë”°ë¼ê°€ê¸° ì‹¤í—˜ / Wall following experiments
```

## ğŸš€ ì‹¤í–‰ ë°©ë²• / How to Run

### ë©”ì¸ ì‹œìŠ¤í…œ ì‹¤í–‰ / Run Main System

```bash
cd src
python3 main.py
```

ë˜ëŠ” í”„ë¡œì íŠ¸ ë£¨íŠ¸ì—ì„œ / Or from project root:

```bash
python3 src/main.py
```

### ì‹œìŠ¤í…œ ë™ì‘ íë¦„ / System Workflow

1. **Part 1: ë¼ì¸íŠ¸ë ˆì´ì‹± / Line Tracing**
   - ì¹´ë©”ë¼ë¡œ ë¼ì¸ ê°ì§€ (CV + ML í•˜ì´ë¸Œë¦¬ë“œ) / Line detection using camera (CV + ML hybrid)
   - ML ëª¨ë¸ë¡œ ì‹ í˜¸ë“± ê°ì§€ (Red/Green) / Traffic light detection using ML model (Red/Green)
   - ì´ˆë¡ë¶ˆ ê°ì§€ ì‹œ Part 2ë¡œ ì „í™˜ / Switch to Part 2 when green light detected
   - ë¹¨ê°„ë¶ˆ ê°ì§€ ì‹œ ì •ì§€ í›„ ì´ˆë¡ë¶ˆ ëŒ€ê¸° / Stop and wait for green light when red light detected

2. **Part 2: ì´ˆìŒíŒŒ ì„¼ì„œ ì£¼í–‰ / Ultrasonic Sensor Driving**
   - ì´ˆìŒíŒŒ ì„¼ì„œ ê¸°ë°˜ ê³ ì† ì£¼í–‰ / High-speed driving based on ultrasonic sensors
   - ì¢Œìš° ë²½ ê±°ë¦¬ ì¸¡ì •í•˜ì—¬ ì¤‘ì•™ ìœ ì§€ / Maintain center by measuring left/right wall distances
   - ì½”ë„ˆ/ì§ì„  êµ¬ê°„ ìë™ ê°ì§€ ë° ì†ë„ ì¡°ì ˆ / Automatic corner/straight detection and speed adjustment

## ğŸ”§ ì£¼ìš” ëª¨ë“ˆ / Key Modules

### ë¼ì¸íŠ¸ë ˆì´ì‹± ëª¨ë“ˆ (`src/`) / Line Tracing Module

- **linetracing.py**: ë©”ì¸ ë¡œì§, ì‹ í˜¸ë“± ê°ì§€ ë° ë‹¨ê³„ ì „í™˜ / Main logic, traffic light detection and stage transition
- **linetracing_cv.py**: OpenCV ê¸°ë°˜ ë¼ì¸ ê°ì§€ / OpenCV-based line detection
- **linetracing_ml.py**: TFLite ëª¨ë¸ë¡œ ì‹ í˜¸ë“± ê°ì§€ (Red/Green/CV) / Traffic light detection using TFLite model (Red/Green/CV)
- **linetracing_drive.py**: ëª¨í„°/ì„œë³´ í•˜ë“œì›¨ì–´ ì œì–´ / Motor/servo hardware control
- **linetracing_Judgment.py**: CVì™€ ML íŒë‹¨ ê²°ê³¼ í†µí•© / Integration of CV and ML judgment results

### ì´ˆìŒíŒŒ ì£¼í–‰ ëª¨ë“ˆ / Ultrasonic Driving Module

- **low_defense.py**: ì´ˆìŒíŒŒ ì„¼ì„œ ê¸°ë°˜ ê³ ì† ì£¼í–‰ ì œì–´ / Ultrasonic sensor-based high-speed driving control
  - ì¢Œìš° ì„¼ì„œ ê±°ë¦¬ ì°¨ì´ë¡œ ì¡°í–¥ê° ê³„ì‚° / Calculate steering angle from left/right sensor distance difference
  - ì½”ë„ˆ/ì§ì„  êµ¬ê°„ ìë™ ê°ì§€ / Automatic corner/straight section detection
  - êµ¬ê°„ë³„ ì†ë„ ìë™ ì¡°ì ˆ / Automatic speed adjustment by section

## ğŸ“¦ ì˜ì¡´ì„± / Dependencies

ì£¼ìš” ë¼ì´ë¸ŒëŸ¬ë¦¬ / Main libraries:
- `RPi.GPIO`: GPIO ì œì–´ / GPIO control
- `picamera2`: ì¹´ë©”ë¼ ì œì–´ / Camera control
- `opencv-python-headless`: ì´ë¯¸ì§€ ì²˜ë¦¬ (Raspberry Piìš©) / Image processing (for Raspberry Pi)
- `tflite-runtime`: ML ëª¨ë¸ ì¶”ë¡  / ML model inference
- `numpy`: ìˆ˜ì¹˜ ì—°ì‚° / Numerical computation

### requirements.txt ì‚¬ìš© / Using requirements.txt

```bash
pip install -r requirements.txt
```

ë˜ëŠ” ê°€ìƒí™˜ê²½ì—ì„œ / Or in virtual environment:

```bash
source ~/venvs/mecha/bin/activate
pip install -r requirements.txt
```

## âš™ï¸ ì„¤ì • ë° ì„¤ì¹˜ / Setup and Installation

### ìë™ ì„¤ì¹˜ ìŠ¤í¬ë¦½íŠ¸ / Automated Setup Script

Raspberry Piì—ì„œ ë‹¤ìŒ ëª…ë ¹ì–´ë¡œ ìë™ìœ¼ë¡œ í™˜ê²½ì„ ì„¤ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:  
You can automatically set up the environment on Raspberry Pi with the following command:

```bash
cd settings
chmod +x setting.sh
./setting.sh
```

### ì„¤ì¹˜ ìŠ¤í¬ë¦½íŠ¸ ê¸°ëŠ¥ / Setup Script Features

`settings/setting.sh` ìŠ¤í¬ë¦½íŠ¸ëŠ” ë‹¤ìŒ ì‘ì—…ì„ ìë™ìœ¼ë¡œ ìˆ˜í–‰í•©ë‹ˆë‹¤:  
The `settings/setting.sh` script automatically performs the following tasks:

1. **ì‹œìŠ¤í…œ íŒ¨í‚¤ì§€ ì—…ë°ì´íŠ¸ / System Package Update**
   - `apt update` ë° í•„ìˆ˜ íŒ¨í‚¤ì§€ ì„¤ì¹˜ / `apt update` and install essential packages
   - Python3, OpenCV, Picamera2, GPIO ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜ / Install Python3, OpenCV, Picamera2, GPIO libraries

2. **ê°€ìƒí™˜ê²½ ìƒì„± / Virtual Environment Creation**
   - `~/venvs/mecha` ê²½ë¡œì— ê°€ìƒí™˜ê²½ ìƒì„± / Create virtual environment at `~/venvs/mecha`
   - ì‹œìŠ¤í…œ ì‚¬ì´íŠ¸ íŒ¨í‚¤ì§€ì™€ ì—°ë™ / Link with system site packages
   - `.bashrc`ì— ìë™ í™œì„±í™” ì¶”ê°€ / Add auto-activation to `.bashrc`

3. **Python íŒ¨í‚¤ì§€ ì„¤ì¹˜ / Python Package Installation**
   - pip ì—…ê·¸ë ˆì´ë“œ / Upgrade pip
   - í•„ìˆ˜ íŒ¨í‚¤ì§€ ì„¤ì¹˜: `tflite-runtime`, `numpy`, `opencv-python-headless` / Install essential packages

4. **ì˜ì¡´ì„± í™•ì¸ / Dependency Check**
   - `Check_dependencies_pi.py` ì‹¤í–‰í•˜ì—¬ ì„¤ì¹˜ í™•ì¸ / Run `Check_dependencies_pi.py` to verify installation

5. **ì¹´ë©”ë¼ í™•ì¸ / Camera Check**
   - `cameracheck.py` ì‹¤í–‰í•˜ì—¬ ì¹´ë©”ë¼ ë™ì‘ í™•ì¸ / Run `cameracheck.py` to verify camera operation

### ìˆ˜ë™ ì„¤ì¹˜ / Manual Installation

ìë™ ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì‚¬ìš©í•˜ì§€ ì•ŠëŠ” ê²½ìš°, ë‹¤ìŒ ëª…ë ¹ì–´ë¥¼ ìˆœì„œëŒ€ë¡œ ì‹¤í–‰í•˜ì„¸ìš”:  
If you prefer manual installation, run the following commands in order:

```bash
# ì‹œìŠ¤í…œ íŒ¨í‚¤ì§€ ì„¤ì¹˜ / Install system packages
sudo apt update
sudo apt install -y python3 python3-pip python3-venv python3-opencv python3-picamera2 python3-gpiozero

# ê°€ìƒí™˜ê²½ ìƒì„± / Create virtual environment
python3 -m venv ~/venvs/mecha --system-site-packages
source ~/venvs/mecha/bin/activate

# Python íŒ¨í‚¤ì§€ ì„¤ì¹˜ / Install Python packages
pip install --upgrade pip
pip install tflite-runtime numpy opencv-python-headless
```

### ê°€ìƒí™˜ê²½ í™œì„±í™” / Activate Virtual Environment

ì„¤ì¹˜ í›„ ê°€ìƒí™˜ê²½ì„ í™œì„±í™”í•˜ì„¸ìš”:  
After installation, activate the virtual environment:

```bash
source ~/venvs/mecha/bin/activate
```

í„°ë¯¸ë„ì„ ì¬ì‹œì‘í•˜ë©´ ìë™ìœ¼ë¡œ í™œì„±í™”ë©ë‹ˆë‹¤.  
The virtual environment will auto-activate when you restart your terminal.

## ğŸ“ ì°¸ê³ ì‚¬í•­ / Notes

- **ìµœì¢… ëª¨ë¸ / Final Model**: `models/gpu_model_lite.tflite` (ì‹ í˜¸ë“± ê°ì§€ìš© / for traffic light detection)
- **ë¡œê·¸ ì´ë¯¸ì§€ / Log Images**: `logs/line_log/` í´ë” (ë””ë²„ê¹…ìš©, í•„ìš”ì‹œ í™œì„±í™” / for debugging, enable when needed)
- **í…ŒìŠ¤íŠ¸ ì½”ë“œ / Test Code**: `test/` í´ë” ì°¸ê³  / See `test/` folder
- **ì‹¤í—˜ ì½”ë“œ / Experimental Code**: `experiments/` í´ë” (ì°¸ê³ ìš©, ì‚¬ìš© ì•ˆ í•¨ / for reference, not used)
